---
title: "API Hello World"
sidebarTitle: "Hello World"
---

The Vast.ai REST API gives you programmatic control over GPU instances — useful for automation, CI/CD pipelines, or building your own tooling on top of Vast.

This guide walks through the complete instance lifecycle: authenticate, search for a GPU, rent it, wait for it to boot, and clean up. By the end you'll understand the core API calls needed to manage instances without touching the web console.

## Prerequisites

- A Vast.ai account with credit
- `curl` installed

## 1. Get Your API Key

Generate an API key from the Vast.ai console at [cloud.vast.ai](https://cloud.vast.ai/). Copy the key — you'll need it for every API call.

Export it as an environment variable:

```bash
export VAST_API_KEY="your-api-key-here"
```

## 2. Verify Authentication

Confirm your key works by listing your current instances. If you have none, this returns an empty list.

```bash
curl -s -H "Authorization: Bearer $VAST_API_KEY" \
  "https://console.vast.ai/api/v0/instances/"
```

```json
{
  "instances_found": 0,
  "instances": []
}
```

<Note>
If you get a `401` or `403`, double-check your API key.
</Note>

## 3. Search for GPUs

Find available machines using the bundles endpoint. This query returns the 3 cheapest on-demand RTX 4090s (sorted by total $/hr, including storage):

```bash
curl -s -H "Authorization: Bearer $VAST_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "verified": {"eq": true},
    "rentable": {"eq": true},
    "gpu_name": {"eq": "RTX 4090"},
    "num_gpus": {"eq": 1},
    "direct_port_count": {"gte": 1},
    "order": [["dph_total", "asc"]],
    "type": "on-demand",
    "limit": 3
  }' \
  "https://console.vast.ai/api/v0/bundles/"
```

Here's what each parameter does:

| Parameter | Value | Meaning |
|-----------|-------|---------|
| `verified` | `{"eq": true}` | Only machines verified by Vast.ai (identity-checked hosts) |
| `rentable` | `{"eq": true}` | Only machines currently available to rent |
| `gpu_name` | `{"eq": "RTX 4090"}` | Filter to a specific GPU model |
| `num_gpus` | `{"eq": 1}` | Exactly 1 GPU per instance |
| `direct_port_count` | `{"gte": 1}` | At least 1 directly accessible port (needed for SSH) |
| `order` | `[["dph_total", "asc"]]` | Sort by total cost per hour, cheapest first |
| `type` | `"on-demand"` | On-demand pricing (vs. interruptible spot/bid) |
| `limit` | `3` | Return at most 3 results |

The response contains an `offers` array. Note the `id` of the offer you want — you'll use it in the next step.

<Tip>
All filters use operator objects like `{"eq": true}` or `{"gte": 1}`. The sort field must be `"order": [["field", "direction"]]` (array of arrays).
</Tip>

## 4. Create an Instance

Rent the machine by sending a PUT request with your Docker image and disk size. Replace `OFFER_ID` with the `id` from step 3.

```bash
curl -s -H "Authorization: Bearer $VAST_API_KEY" \
  -H "Content-Type: application/json" \
  -X PUT \
  -d '{
    "image": "pytorch/pytorch:2.4.0-cuda12.4-cudnn9-runtime",
    "disk": 20,
    "onstart": "echo hello && nvidia-smi"
  }' \
  "https://console.vast.ai/api/v0/asks/OFFER_ID/"
```

```json
{
  "success": true,
  "new_contract": 12345678,
  "instance_api_key": "d15a..."
}
```

Save the `new_contract` value — this is your instance ID. The response also includes an `instance_api_key` for programmatic access to the instance.

## 5. Wait Until Ready

The instance needs time to pull the Docker image and boot. Poll the status endpoint until `actual_status` is `"running"`. Replace `INSTANCE_ID` with the `new_contract` value from step 4.

```bash
curl -s -H "Authorization: Bearer $VAST_API_KEY" \
  "https://console.vast.ai/api/v0/instances/INSTANCE_ID/"
```

Example response:

```json
{
  "instances": {
    "actual_status": "loading",
    "ssh_host": "...",
    "ssh_port": 12345
  }
}
```

The `actual_status` field progresses through these states:

| `actual_status` | Meaning |
|-----------------|---------|
| `null` | Instance is being provisioned |
| `"loading"` | Docker image is downloading |
| `"running"` | Ready to use |

Poll every 10 seconds. Boot time is typically 1–5 minutes depending on the Docker image size.

Once `actual_status` is `"running"`, you can connect via SSH using the `ssh_host` and `ssh_port` from the response.

## 6. Clean Up

When you're done, destroy the instance to stop all billing.

To pause an instance temporarily instead of destroying it, you can **stop** it. Stopping halts compute billing but disk storage charges continue.

**Stop** (pauses compute, disk charges continue):

```bash
curl -s -H "Authorization: Bearer $VAST_API_KEY" \
  -H "Content-Type: application/json" \
  -X PUT \
  -d '{"state": "stopped"}' \
  "https://console.vast.ai/api/v0/instances/INSTANCE_ID/"
```

**Destroy** (removes everything):

```bash
curl -s -H "Authorization: Bearer $VAST_API_KEY" \
  -X DELETE \
  "https://console.vast.ai/api/v0/instances/INSTANCE_ID/"
```

Both return `{"success": true}`.

## Next Steps

You've now completed the full instance lifecycle through the API: authentication, search, creation, polling, and teardown. From here:

- **Connect via SSH** — Once an instance is running, use the `ssh_host` and `ssh_port` from the status response to SSH in. See the [SSH guide](/documentation/instances/connect/ssh) for setup.
- **Use templates** — Avoid repeating image and config parameters on every create call. The [Templates API guide](/api-reference/creating-and-using-templates-with-api) covers creating, sharing, and launching from templates.
