---
title: Serverless Overview
description: Learn how to use Vast.ai's Serverless system to automate the provisioning of GPU workers to match the dynamic computational needs of your workloads.
"canonical": "/documentation/serverless"
---

<script type="application/ld+json" dangerouslySetInnerHTML={{
  __html: JSON.stringify({
    "@context": "https://schema.org",
    "@type": "TechArticle",
    "headline": "Vast.ai Serverless Overview",
    "description": "Introduction to Vast.ai's Serverless system for automating GPU worker provisioning with key features including dynamic scaling, global GPU fleet, fast cold-start times, and custom worker types.",
    "author": {
      "@type": "Organization",
      "name": "Vast.ai"
    },
    "articleSection": "Serverless Documentation",
    "keywords": ["serverless", "GPU", "dynamic scaling", "AI inference", "vast.ai", "autoscaling"]
  })
}} />

Use Vast.ai's Serverless system to automate the provisioning of GPU workers to match the dynamic computational needs of your workloads. This system ensures efficient and cost-effective scaling for AI inference and other GPU computing tasks.

## Key Features

- **Dynamic Scaling**: Automatically scale your AI inference up or down based on customizable performance metrics.
- **Global GPU Fleet**: Leverage Vastâ€™s global fleet of powerful, affordable GPUs for your computational needs.
- **Fast Cold-Start Times**: Minimize cold-start times with a reserve pool of workers that can spin up in seconds.
- **Metrics and Debugging**: Access ample metrics and debugging tools for your serverless usage, including logs and Jupyter/SSH access.
- **Performance Exploration**: Perform in-depth performance exploration to optimize based on performance and price metrics.
- **Custom Worker Types**: Define custom worker types through CLI search filters and create commands, supporting multiple worker types per endpoint.

