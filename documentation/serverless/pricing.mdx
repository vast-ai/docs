---
title: Pricing
description: Learn how Vast.ai Serverless pricing works - GPU recruitment, endpoint suspension, and stopping.
---

Vast.ai Serverless offers pay-as-you-go pricing for all workloads at the same rates as Vast.ai's non-Serverless GPU instances. This guide explains how pricing works.

## GPU Recruitment

As the Serverless engine takes requests, it will automatically scale its number of workers up or down depending on the incoming and forecasted demand. When scaling up, the engine searches over the Vast.ai marketplace for GPU instances that offer the best performance / price ratio. Once determined, the GPU instance(s) is recruited into the Serverless engine, and its cost ($/hr) is added to the running sum of all GPU instances running on your Serverless engine.&#x20;

As the request demand falls off, the engine will remove GPU instance(s) and your credit account immediatley stops being charged for those corresponding instance(s).

Visit the [Billing Help](https://docs.vast.ai/billing#ugwiY) page to see details on GPU instance costs.

## Suspending an Endpoint

By suspending an Endpoint, the Endpoint will no longer recruit any new GPU instances, but will continue to use the instances it currently has. This is a way to cap the number of instances an Endpoint can manage, and therefore limit costs.&#x20;

## Stopping an Endpoint

Stopping an Endpoint will pause the recruitment of GPU instances, and put the existing instances into the "Stopped" state, preventing any work from being sent to the Endpoint group. The instances will still charge the small storage cost, but active rental and bandwidth costs will not be charged to the user account.&#x20;

